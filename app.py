import os
import re
import asyncio
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, MessageHandler, CommandHandler, CallbackQueryHandler, ContextTypes, filters
import speech_recognition as sr
from pydub import AudioSegment

TOKEN = os.getenv("TELEGRAM_TOKEN")
recognizer = sr.Recognizer()
user_transcripts = {}  # Ø­Ø§ÙØ¸Ù‡ Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ù…ØªÙ† Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±

# Ù¾Ø§Ø³Ø® Ø¨Ù‡ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ğŸ™ï¸ Ø³Ù„Ø§Ù…! Ø®ÙˆØ´ Ø§ÙˆÙ…Ø¯ÛŒ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† ğŸ§\n\nğŸ“¤ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ (Voice ÛŒØ§ MP3) Ø§Ø±Ø³Ø§Ù„ Ú©Ù† ØªØ§ Ù…ØªÙ†Ø´ Ø±Ùˆ Ø¨Ø±Ø§Øª Ø¨Ù†ÙˆÛŒØ³Ù… âœï¸"
    )

# Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª Ø³Ø§Ø®ØªÚ¯ÛŒ
async def show_fake_progress(update: Update, context: ContextTypes.DEFAULT_TYPE) -> Update:
    progress_phases = [
        "ğŸ§ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ù‡Ø³ØªÛŒÙ…...\nâ–â–â–â–â–â–â–â–",
        "ğŸ§ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ù‡Ø³ØªÛŒÙ…...\nâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚",
        "ğŸ§ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ù‡Ø³ØªÛŒÙ…...\nâ–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ",
        "ğŸ§ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ù‡Ø³ØªÛŒÙ…...\nâ–â–‚â–ƒâ–„â–„â–„â–„â–„â–„",
        "ğŸ§ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ù‡Ø³ØªÛŒÙ…...\nâ–â–‚â–ƒâ–„â–…â–…â–…â–…",
        "ğŸ§ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ù‡Ø³ØªÛŒÙ…...\nâ–â–‚â–ƒâ–„â–…â–†â–†â–†",
        "ğŸ§ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ù‡Ø³ØªÛŒÙ…...\nâ–â–‚â–ƒâ–„â–…â–†â–‡â–‡",
        "ğŸ§ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ù‡Ø³ØªÛŒÙ…...\nâ–â–‚â–ƒâ–„â–…â–†â–‡â–ˆ",
    ]
    msg = await update.message.reply_text(progress_phases[0])
    for phase in progress_phases[1:]:
        await asyncio.sleep(0.4)
        await msg.edit_text(phase)
    return msg

# Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª
async def process_audio(update: Update, context: ContextTypes.DEFAULT_TYPE, file_path: str):
    progress_msg = await show_fake_progress(update, context)

    audio = AudioSegment.from_file(file_path)
    audio.export("converted.wav", format="wav")

    with sr.AudioFile("converted.wav") as source:
        audio_data = recognizer.record(source)
        try:
            result = recognizer.recognize_google(audio_data, language="fa-IR", show_all=True)
            if not result or "alternative" not in result:
                await progress_msg.delete()
                await update.message.reply_text("âŒ Ù…ØªÙ†ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†.")
                return

            full_text = result["alternative"][0]["transcript"]
            sentences = re.split(r'[.ØŒØ›!ØŸ]\s*', full_text)
            sentences = [s.strip() for s in sentences if s.strip()]

            await progress_msg.delete()

            for sentence in sentences:
                await update.message.reply_text(f"ğŸ“ {sentence}")

            # Ø°Ø®ÛŒØ±Ù‡ Ù…ØªÙ† Ú©Ø§Ø±Ø¨Ø±
            user_transcripts[update.effective_user.id] = sentences

            # Ø§Ø±Ø³Ø§Ù„ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
            keyboard = [
                [
                    InlineKeyboardButton("ğŸ“„ Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ (.txt)", callback_data="send_txt"),
                    InlineKeyboardButton("ğŸ¬ Ø¯Ø±ÛŒØ§ÙØª Ø²ÛŒØ±Ù†ÙˆÛŒØ³ (.srt)", callback_data="send_srt"),
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await update.message.reply_text("ğŸ’¾ Ú©Ø¯ÙˆÙ… ÙØ§ÛŒÙ„ Ø±Ùˆ Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØŸ", reply_markup=reply_markup)

        except sr.UnknownValueError:
            await progress_msg.delete()
            await up
